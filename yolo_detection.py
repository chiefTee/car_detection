# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A3Pp7z-1vpq4tUAFFnnyae15D8UKS2PH
"""

!pip install ultralytics keyboard ipywidgets --quiet

import cv2
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from ultralytics import YOLO
from IPython.display import display, clear_output
import ipywidgets as widgets
import keyboard

import cv2
from ultralytics import YOLO
import matplotlib.pyplot as plt
import ipywidgets as widgets
import numpy as np

model = YOLO("yolov8n.pt")

cap = cv2.VideoCapture(r'/content/drive/MyDrive/4K Road traffic video for object detection and tracking - free download now!.mp4')

if not cap.isOpened():
    raise IOError("Unable to open video source")

frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
fps = int(cap.get(cv2.CAP_PROP_FPS))

out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

frame_count = 0
saved_videos_count = 0

all_detected_cars = {}
active_cars = set()
next_car_id = 1

fig, ax = plt.subplots(figsize=(12, 8))
plt.ion()

video_widget = widgets.Output()
display(video_widget)

def iou(box1, box2):
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])

    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])

    iou = intersection / float(area1 + area2 - intersection)
    return iou

while True:
    ret, frame = cap.read()
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break

    frame_count += 1

    results = model(frame)

    boxes = results[0].boxes
    current_frame_cars = set()

    for box in boxes:
        if int(box.cls[0]) == 2:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = box.conf[0]

            matched_id = None
            for car_id, (prev_box, last_seen) in all_detected_cars.items():
                if iou((x1, y1, x2, y2), prev_box) > 0.5:
                    matched_id = car_id
                    break

            if matched_id is None:
                car_id = next_car_id
                next_car_id += 1
                all_detected_cars[car_id] = ((x1, y1, x2, y2), frame_count)
                label = f'New car {car_id} {conf:.2f}'
                color = (0, 255, 0)
            else:
                all_detected_cars[matched_id] = ((x1, y1, x2, y2), frame_count)
                label = f'Tracked car {matched_id} {conf:.2f}'
                color = (0, 255, 255)
                car_id = matched_id

            current_frame_cars.add(car_id)


            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

    active_cars = current_frame_cars

    text_x = frame_width - 300
    text_y = 50
    cv2.putText(frame, f'Frame: {frame_count}', (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    cv2.putText(frame, f'Active cars: {len(active_cars)}', (text_x, text_y + 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    with video_widget:
        ax.clear()
        ax.imshow(frame_rgb)
        ax.axis('off')
        plt.tight_layout()
        plt.pause(0.01)
        video_widget.clear_output(wait=True)

    if current_frame_cars:
        out.write(frame)
        saved_videos_count += 1

    if saved_videos_count >= 150:
        print("Saved 150 videos with detected cars. Stopping...")
        break

    if plt.waitforbuttonpress(timeout=0.1):
        break

cap.release()
out.release()
plt.close(fig)

print("Video processing complete. Output saved as 'output.mp4'")

